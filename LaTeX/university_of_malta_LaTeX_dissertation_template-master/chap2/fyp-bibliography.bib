@article{khramtsov_deep_2019,
	title = {Deep {Learning} for {Morphological} {Classification} of {Galaxies} from {SDSS}},
	volume = {32},
	url = {https://ui.adsabs.harvard.edu/abs/2019OAP....32...21K},
	doi = {10.18524/1810-4215.2019.32.182092},
	abstract = {We present the results of applying deep convolutional neural network to the images of redshift-limited (z {\textless} 0 . 1) sample of ∼ 300000 galaxies from the SDSS DR9. We aimed to classify galaxies into the two classes: Elliptical and Spiral. To create the training sample, we used a set of ∼ 6000 galaxies from our previous work with visually inspected morphological types, and also added 80000 well-confirmed galaxies from Galaxy Zoo 2 dataset, that were also classified visually. With a given sample of ∼ 86000 galaxies, we used the deep neural network, namely Xception, to provide a classification of g-r-i composite images (25 arcsec in each axis in size) of galaxies. Keeping in the mind a relatively small training dataset, we provided the data augmentation (horizontal and vertical flips, random shifts on ± 10 pixels , and rotations within 180 degrees), that was randomly applied to the images during learning. The data augmentation is a key technique within our algorithm to display the variative nature of the observed galaxies, and avoid overfitting problem. We compared our classification result with the Support Vector Machine (SVM) classification performed on the SDSS photometric data (absolute magnitudes, colour indices, inverse concentration index, ratios of semiaxes, etc.), and proposed a method to learn the benefits from both approaches (Deep Learning and photometric classification). We show the common mistakes of both algorithms, and propose to stack these two approaches to block these mistakes, with a main goal to increase the overall classification quality of SDSS galaxies.},
	urldate = {2022-08-10},
	journal = {Odessa Astronomical Publications},
	author = {Khramtsov, V. and Dobrycheva, D. V. and Vasylenko, M. Yu. and Akhmetov, V. S.},
	month = jan,
	year = {2019},
	note = {ADS Bibcode: 2019OAP....32...21K},
	keywords = {galaxies, machine learning, morphological classification},
	pages = {21},
	file = {Full Text:C\:\\Users\\rober\\Zotero\\storage\\64GTK8PA\\Khramtsov et al. - 2019 - Deep Learning for Morphological Classification of .pdf:application/pdf},
}

@article{way_galaxy_2011,
	title = {Galaxy {Zoo} {Morphology} and {Photometric} {Redshifts} in the {Sloan} {Digital} {Sky} {Survey}},
	volume = {734},
	issn = {0004-637X},
	url = {https://ui.adsabs.harvard.edu/abs/2011ApJ...734L...9W},
	doi = {10.1088/2041-8205/734/1/L9},
	abstract = {It has recently been demonstrated that one can accurately derive galaxy morphology from particular primary and secondary isophotal shape estimates in the Sloan Digital Sky Survey (SDSS) imaging catalog. This was accomplished by applying Machine Learning techniques to the Galaxy Zoo morphology catalog. Using the broad bandpass photometry of the SDSS in combination with precise knowledge of galaxy morphology should help in estimating more accurate photometric redshifts for galaxies. Using the Galaxy Zoo separation for spirals and ellipticals in combination with SDSS photometry we attempt to calculate photometric redshifts. In the best case we find that the root-mean-square error for luminous red galaxies classified as ellipticals is as low as 0.0118. Given these promising results we believe better photometric redshift estimates for all galaxies in the SDSS ({\textasciitilde}350 million) will be feasible if researchers can also leverage their derived morphologies via Machine Learning. These initial results look to be promising for those interested in estimating weak lensing, baryonic acoustic oscillation, and other fields dependent upon accurate photometric redshifts.},
	urldate = {2022-08-10},
	journal = {The Astrophysical Journal},
	author = {Way, M. J.},
	month = jun,
	year = {2011},
	note = {ADS Bibcode: 2011ApJ...734L...9W},
	keywords = {methods: statistical, Astrophysics - Cosmology and Nongalactic Astrophysics, galaxies: distances and redshifts},
	pages = {L9},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\HASXQMWH\\Way - 2011 - Galaxy Zoo Morphology and Photometric Redshifts in.pdf:application/pdf;Submitted Version:C\:\\Users\\rober\\Zotero\\storage\\B5KVRYDB\\Way - 2011 - Galaxy Zoo Morphology and Photometric Redshifts in.pdf:application/pdf},
}

@article{vavilova_machine_2021,
	title = {Machine learning technique for morphological classification of galaxies from the {SDSS} - {I}. {Photometry}-based approach},
	volume = {648},
	copyright = {© ESO 2021},
	issn = {0004-6361, 1432-0746},
	url = {https://www.aanda.org/articles/aa/abs/2021/04/aa38981-20/aa38981-20.html},
	doi = {10.1051/0004-6361/202038981},
	abstract = {{\textless}i{\textgreater}Context.{\textless}i/{\textgreater} Machine learning methods are effective tools in astronomical tasks for classifying objects by their individual features. One of the promising utilities is related to the morphological classification of galaxies at different redshifts.{\textless}i{\textgreater}Aims.{\textless}i/{\textgreater} We use the photometry-based approach for the SDSS data (1) to exploit five supervised machine learning techniques and define the most effective among them for the automated galaxy morphological classification; (2) to test the influence of photometry data on morphology classification; (3) to discuss problem points of supervised machine learning and labeling bias; and (4) to apply the best fitting machine learning methods for revealing the unknown morphological types of galaxies from the SDSS DR9 at {\textless}i{\textgreater}z{\textless}i/{\textgreater} {\textless} 0.1.{\textless}i{\textgreater}Methods.{\textless}i/{\textgreater} We used different galaxy classification techniques: human labeling, multi-photometry diagrams, naive Bayes, logistic regression, support-vector machine, random forest, {\textless}i{\textgreater}k{\textless}i/{\textgreater}-nearest neighbors.{\textless}i{\textgreater}Results.{\textless}i/{\textgreater} We present the results of a binary automated morphological classification of galaxies conducted by human labeling, multi-photometry, and five supervised machine learning methods. We applied it to the sample of galaxies from the SDSS DR9 with redshifts of 0.02 {\textless} {\textless}i{\textgreater}z{\textless}i/{\textgreater} {\textless} 0.1 and absolute stellar magnitudes of −24{\textless}sup{\textgreater}m{\textless}sup/{\textgreater} {\textless} {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}r{\textless}i/{\textgreater}{\textless}sub/{\textgreater} {\textless} −19.4{\textless}sup{\textgreater}m{\textless}sup/{\textgreater}. For the analysis we used absolute magnitudes {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}u{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}g{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}r{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}i{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}z{\textless}i/{\textgreater}{\textless}sub/{\textgreater}; color indices {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}u{\textless}i/{\textgreater}{\textless}sub/{\textgreater} − {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}r{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}g{\textless}i/{\textgreater}{\textless}sub/{\textgreater} − {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}i{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}u{\textless}i/{\textgreater}{\textless}sub/{\textgreater} − {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}g{\textless}i/{\textgreater}{\textless}sub/{\textgreater}, {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}r{\textless}i/{\textgreater}{\textless}sub/{\textgreater} − {\textless}i{\textgreater}M{\textless}i/{\textgreater}{\textless}sub{\textgreater}{\textless}i{\textgreater}z{\textless}i/{\textgreater}{\textless}sub/{\textgreater}; and the inverse concentration index to the center {\textless}i{\textgreater}R{\textless}i/{\textgreater}50/{\textless}i{\textgreater}R{\textless}i/{\textgreater}90. We determined the ability of each method to predict the morphological type, and verified various dependencies of the method’s accuracy on redshifts, human labeling, morphological shape, and overlap of different morphological types for galaxies with the same color indices. We find that the morphology based on the supervised machine learning methods trained over photometric parameters demonstrates significantly less bias than the morphology based on citizen-science classifiers.{\textless}i{\textgreater}Conclusions.{\textless}i/{\textgreater} The support-vector machine and random forest methods with Scikit-learn software machine learning library in Python provide the highest accuracy for the binary galaxy morphological classification. Specifically, the success rate is 96.4\% for support-vector machine (96.1\% early {\textless}i{\textgreater}E{\textless}i/{\textgreater} and 96.9\% late {\textless}i{\textgreater}L{\textless}i/{\textgreater} types) and 95.5\% for random forest (96.7\% early {\textless}i{\textgreater}E{\textless}i/{\textgreater} and 92.8\% late {\textless}i{\textgreater}L{\textless}i/{\textgreater} types). Applying the support-vector machine for the sample of 316 031 galaxies from the SDSS DR9 at {\textless}i{\textgreater}z{\textless}i/{\textgreater} {\textless} 0.1 with unknown morphological types, we found 139 659 {\textless}i{\textgreater}E{\textless}i/{\textgreater} and 176 372 {\textless}i{\textgreater}L{\textless}i/{\textgreater} types among them.},
	language = {en},
	urldate = {2022-08-11},
	journal = {Astronomy \& Astrophysics},
	author = {Vavilova, I. B. and Dobrycheva, D. V. and Vasylenko, M. Yu and Elyiv, A. A. and Melnyk, O. V. and Khramtsov, V.},
	month = apr,
	year = {2021},
	note = {Publisher: EDP Sciences},
	pages = {A122},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\VIILQVXG\\Vavilova et al. - 2021 - Machine learning technique for morphological class.pdf:application/pdf;Snapshot:C\:\\Users\\rober\\Zotero\\storage\\SV99TP3R\\aa38981-20.html:text/html},
}

@article{ma_machine_2019,
	title = {A {Machine} {Learning} {Based} {Morphological} {Classification} of 14,245 {Radio} {AGNs} {Selected} from the {Best}-{Heckman} {Sample}},
	volume = {240},
	issn = {0067-0049},
	url = {https://ui.adsabs.harvard.edu/abs/2019ApJS..240...34M},
	doi = {10.3847/1538-4365/aaf9a2},
	abstract = {We present a morphological classification of 14,245 radio active galactic nuclei (AGNs) into six types, i.e., typical Fanaroff-Riley Class I/II (FRI/II), FRI/II-like bent-tailed, X-shaped radio galaxy, and ringlike radio galaxy, by designing a convolutional neural network based autoencoder, namely MCRGNet, and applying it to a labeled radio galaxy (LRG) sample containing 1442 AGNs and an unlabeled radio galaxy (unLRG) sample containing 14,245 unlabeled AGNs selected from the Best-Heckman sample. We train MCRGNet and implement the classification task by a three-step strategy, i.e., pre-training, fine-tuning, and classification, which combines both unsupervised and supervised learnings. A four-layer dichotomous tree is designed to classify the radio AGNs, which leads to a significantly better performance than the direct six-type classification. On the LRG sample, our MCRGNet achieves a total precision of ∼93\% and an averaged sensitivity of ∼87\%, which are better than those obtained in previous works. On the unLRG sample, whose labels have been human-inspected, the neural network achieves a total precision of ∼80\%. Also, using Sloan Digital Sky Survey Data Release 7 to calculate the r-band absolute magnitude (M opt) and using the flux densities to calculate the radio luminosity (L radio), we find that the distributions of the unLRG sources on the L radio-M opt plane do not show an apparent redshift evolution and could confirm with a sufficiently large sample that there could not exist an abrupt separation between FRIs and FRIIs as reported in some previous works.},
	urldate = {2022-08-24},
	journal = {The Astrophysical Journal Supplement Series},
	author = {Ma, Zhixian and Xu, Haiguang and Zhu, Jie and Hu, Dan and Li, Weitian and Shan, Chenxi and Zhu, Zhenghao and Gu, Liyi and Li, Jinjin and Liu, Chengze and Wu, Xiangping},
	month = feb,
	year = {2019},
	note = {ADS Bibcode: 2019ApJS..240...34M},
	keywords = {Astrophysics - Astrophysics of Galaxies, galaxies: statistics, methods: data analysis, catalogs, radio continuum: galaxies, techniques: miscellaneous},
	pages = {34},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\3XZSRTYC\\Ma et al. - 2019 - A Machine Learning Based Morphological Classificat.pdf:application/pdf;Submitted Version:C\:\\Users\\rober\\Zotero\\storage\\P8CMJKL9\\Ma et al. - 2019 - A Machine Learning Based Morphological Classificat.pdf:application/pdf},
}

@article{vasylenko_verification_2019,
	title = {Verification of {Machine} {Learning} {Methods} for {Binary} {Morphological} {Classification} of {Galaxies} from {SDSS}},
	volume = {32},
	url = {https://ui.adsabs.harvard.edu/abs/2019OAP....32...46V},
	doi = {10.18524/1810-4215.2019.32.182538},
	abstract = {We present a study on the verification of Machine Learning methods to be applied for binary morphological classification of galaxies. With this aim we used the sample of 60561 galaxies from the SDSSDR9 survey with a redshift of 0.02 {\textless} z {\textless} 0.06 and absolute magnitudes of - 24m {\textless} Mr {\textless} -19.4m. We applied the following classification methods using own code in Python to predict correctly the morphology of Late and Early galaxies: Naive Bayes, Random Forest, Support Vector Machines, Logistic Regression, and k-Nearest Neighbor algorithm. To study the classifier, we used absolute magnitudes Mu, Mg, Mr, Mi,Mz, color indices Mu- Mr ,Mg- Mi,Mu- Mg,Mr - Mz, and inverse concentration index to the center R50/R90. We compared these new results with previous one made with the KNIME Analytics Platform 3.5.3. It turned out that Random Forest and Support Vector Machine Classifiers provide a highest accuracy, as in the previous study, but with help our code in Python we increased an accuracy from 92.9 \% of correctly classified (96\% ± E and 84\% ± L ) to 94,6\% (96,9\% ± E and 89,7 \% ± L). The accuracy of the remaining methods also grew by 88\% to 93\%. So, using these classifiers and the data on color indices, absolute magnitudes, inverse concentration index of galaxies with visual morphological types, we were able to classify 60561 galaxies from the SDSSDR9 with unknown morphological types and found 22301 E and 38260 L types among them.},
	urldate = {2022-08-24},
	journal = {Odessa Astronomical Publications},
	author = {Vasylenko, M. Yu. and Dobrycheva, D. V. and Vavilova, I. B. and Melnyk, O. V. and Elyiv, A. A.},
	month = jan,
	year = {2019},
	note = {ADS Bibcode: 2019OAP....32...46V},
	keywords = {galaxies, morphological classification, machine learning.},
	pages = {46},
	file = {Full Text:C\:\\Users\\rober\\Zotero\\storage\\I7FW9IY7\\Vasylenko et al. - 2019 - Verification of Machine Learning Methods for Binar.pdf:application/pdf},
}

@article{dominguez_sanchez_improving_2018,
	title = {Improving galaxy morphologies for {SDSS} with {Deep} {Learning}},
	volume = {476},
	issn = {0035-8711},
	url = {https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.3661D},
	doi = {10.1093/mnras/sty338},
	abstract = {We present a morphological catalogue for ∼670 000 galaxies in the Sloan Digital Sky Survey in two flavours: T-type, related to the Hubble sequence, and Galaxy Zoo 2 (GZ2 hereafter) classification scheme. By combining accurate existing visual classification catalogues with machine learning, we provide the largest and most accurate morphological catalogue up to date. The classifications are obtained with Deep Learning algorithms using Convolutional Neural Networks (CNNs). We use two visual classification catalogues, GZ2 and Nair \& Abraham (2010), for training CNNs with colour images in order to obtain T-types and a series of GZ2 type questions (disc/features, edge-on galaxies, bar signature, bulge prominence, roundness, and mergers). We also provide an additional probability enabling a separation between pure elliptical (E) from S0, where the T-type model is not so efficient. For the T-type, our results show smaller offset and scatter than previous models trained with support vector machines. For the GZ2 type questions, our models have large accuracy ({\textgreater}97 per cent), precision and recall values ({\textgreater}90 per cent), when applied to a test sample with the same characteristics as the one used for training. The catalogue is publicly released with the paper.},
	urldate = {2022-08-24},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Domínguez Sánchez, H. and Huertas-Company, M. and Bernardi, M. and Tuccillo, D. and Fischer, J. L.},
	month = feb,
	year = {2018},
	note = {ADS Bibcode: 2018MNRAS.476.3661D},
	keywords = {Astrophysics - Astrophysics of Galaxies, catalogues, galaxies: structure, methods: observational},
	pages = {3661--3676},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\KDPG5P7R\\Domínguez Sánchez et al. - 2018 - Improving galaxy morphologies for SDSS with Deep L.pdf:application/pdf;Submitted Version:C\:\\Users\\rober\\Zotero\\storage\\CKMEP98Z\\Domínguez Sánchez et al. - 2018 - Improving galaxy morphologies for SDSS with Deep L.pdf:application/pdf},
}

@article{dieleman_rotation-invariant_2015,
	title = {Rotation-invariant convolutional neural networks for galaxy morphology prediction},
	volume = {450},
	issn = {0035-8711},
	url = {https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D},
	doi = {10.1093/mnras/stv632},
	abstract = {Measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. Surveys such as the Sloan Digital Sky Survey have resulted in the availability of very large collections of images, which have permitted population-wide analyses of galaxy morphology. Morphological analysis has traditionally been carried out mostly via visual inspection by trained experts, which is time consuming and does not scale to large (≳104) numbers of images. Although attempts have been made to build automated classification systems, these have not been able to achieve the desired level of accuracy. The Galaxy Zoo project successfully applied a crowdsourcing strategy, inviting online users to classify images by answering a series of questions. Unfortunately, even this approach does not scale well enough to keep up with the increasing availability of galaxy images. We present a deep neural network model for galaxy morphology classification which exploits translational and rotational symmetry. It was developed in the context of the Galaxy Challenge, an international competition to build the best model for morphology classification based on annotated images from the Galaxy Zoo project. For images with high agreement among the Galaxy Zoo participants, our model is able to reproduce their consensus with near-perfect accuracy ({\textgreater}99 per cent) for most questions. Confident model predictions are highly accurate, which makes the model suitable for filtering large collections of images and forwarding challenging images to experts for manual annotation. This approach greatly reduces the experts' workload without affecting accuracy. The application of these algorithms to larger sets of training data will be critical for analysing results from future surveys such as the Large Synoptic Survey Telescope.},
	urldate = {2022-08-24},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Dieleman, Sander and Willett, Kyle W. and Dambre, Joni},
	month = jun,
	year = {2015},
	note = {ADS Bibcode: 2015MNRAS.450.1441D},
	keywords = {Astrophysics - Astrophysics of Galaxies, Astrophysics - Instrumentation and Methods for Astrophysics, methods: data analysis, Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, techniques: image processing, catalogues, Computer Science - Neural and Evolutionary Computing, galaxies: general, Statistics - Machine Learning},
	pages = {1441--1459},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\3AV68YZN\\Dieleman et al. - 2015 - Rotation-invariant convolutional neural networks f.pdf:application/pdf;Submitted Version:C\:\\Users\\rober\\Zotero\\storage\\EKM3LPRX\\Dieleman et al. - 2015 - Rotation-invariant convolutional neural networks f.pdf:application/pdf},
}

@article{banerji_galaxy_2010,
	title = {Galaxy {Zoo}: reproducing galaxy morphologies via machine learning},
	volume = {406},
	issn = {0035-8711},
	shorttitle = {Galaxy {Zoo}},
	url = {https://ui.adsabs.harvard.edu/abs/2010MNRAS.406..342B},
	doi = {10.1111/j.1365-2966.2010.16713.x},
	abstract = {We present morphological classifications obtained using machine learning for objects in the Sloan Digital Sky Survey DR6 that have been classified by Galaxy Zoo into three classes, namely early types, spirals and point sources/artefacts. An artificial neural network is trained on a subset of objects classified by the human eye, and we test whether the machine-learning algorithm can reproduce the human classifications for the rest of the sample. We find that the success of the neural network in matching the human classifications depends crucially on the set of input parameters chosen for the machine-learning algorithm. The colours and parameters associated with profile fitting are reasonable in separating the objects into three classes. However, these results are considerably improved when adding adaptive shape parameters as well as concentration and texture. The adaptive moments, concentration and texture parameters alone cannot distinguish between early type galaxies and the point sources/artefacts. Using a set of 12 parameters, the neural network is able to reproduce the human classifications to better than 90 per cent for all three morphological classes. We find that using a training set that is incomplete in magnitude does not degrade our results given our particular choice of the input parameters to the network. We conclude that it is promising to use machine-learning algorithms to perform morphological classification for the next generation of wide-field imaging surveys and that the Galaxy Zoo catalogue provides an invaluable training set for such purposes. This publication has been made possible by the participation of more than 100000 volunteers in the Galaxy Zoo project. Their contributions are individually acknowledged at http://www.galaxyzoo.org/Volunteers.aspx. E-mail: mbanerji@ast.cam.ac.uk ‡ Einstein Fellow.},
	urldate = {2022-08-24},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Banerji, Manda and Lahav, Ofer and Lintott, Chris J. and Abdalla, Filipe B. and Schawinski, Kevin and Bamford, Steven P. and Andreescu, Dan and Murray, Phil and Raddick, M. Jordan and Slosar, Anze and Szalay, Alex and Thomas, Daniel and Vandenberg, Jan},
	month = jul,
	year = {2010},
	note = {ADS Bibcode: 2010MNRAS.406..342B},
	keywords = {Astrophysics - Astrophysics of Galaxies, methods: data analysis, Astrophysics - Cosmology and Nongalactic Astrophysics, galaxies: general},
	pages = {342--353},
	file = {Accepted Version:C\:\\Users\\rober\\Zotero\\storage\\FMYNEQ5H\\Banerji et al. - 2010 - Galaxy Zoo reproducing galaxy morphologies via ma.pdf:application/pdf;Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\E2LM24S7\\Banerji et al. - 2010 - Galaxy Zoo reproducing galaxy morphologies via ma.pdf:application/pdf},
}

@article{reza_galaxy_2021,
	title = {Galaxy morphology classification using automated machine learning},
	volume = {37},
	issn = {2213-1337},
	url = {https://ui.adsabs.harvard.edu/abs/2021A%26C....3700492R/abstract},
	doi = {10.1016/j.ascom.2021.100492},
	abstract = {In this paper, we apply five different machine learning algorithms to classify samples into four categories - spirals, ellipticals, mergers and stars (don't know) using data from the Sloan Digital Sky Survey to assess the feasibility of using machine learning methods for future surveys. Classifying mergers as a separate class poses a challenge as this category is easily confused with both ellipticals and spirals, and as a result, most previous studies have not included mergers as a distinct morphological class. The dataset is highly imbalanced with the number of ellipticals/spirals being much larger than the number of stars/mergers, and this is another challenge we aim to address. Starting with 62 features, we perform principal component analysis and use the 25 most significant principal components as inputs to the machine learning models. We compare our results with the Galaxy Zoo labels and obtain an overall test accuracy of 98.2\% and 97.5\% using Artificial Neural Network and ExtraTrees respectively. However, ExtraTrees outperforms Neural Network in classifying mergers and stars. We also perform a parameter sensitivity test to compare the relative importance of different categories of features on the model's performance. Finally, we address the class imbalance problem and examine the effects of different sampling strategies. Our results show that the use of a balanced dataset with a large number of training samples leads to high recall values for the minority classes, and that oversampling methods lead to better performance than undersampling techniques.},
	language = {en},
	urldate = {2022-08-25},
	journal = {Astronomy and Computing, Volume 37, article id. 100492.},
	author = {Reza, Moonzarin},
	month = oct,
	year = {2021},
	pages = {100492},
}

@article{farias_mask_2020,
	title = {Mask galaxy: {Morphological} segmentation of galaxies},
	volume = {33},
	issn = {2213-1337},
	shorttitle = {Mask galaxy},
	url = {https://ui.adsabs.harvard.edu/abs/2020A%26C....3300420F/abstract},
	doi = {10.1016/j.ascom.2020.100420},
	abstract = {The classification of galaxies based on their morphology is instrumental for the understanding of galaxy formation and evolution. This, in addition to the ever-growing digital astronomical datasets, has motivated the application of advanced computer vision techniques, such as Deep Learning. However, these models have not been implemented as single pipelines that replicate detection, segmentation and morphological classification of galaxies directly from images, as it would be made by experts. We present the first implementation of an automatic machine learning pipeline for detection, segmentation and morphological classification of galaxies based on the Mask R-CNN Deep Learning architecture. This state-of-the-art model of Instance Segmentation also performs image segmentation at the pixel level, which is a recurrent need in the astronomical community. We achieve Mean Average Precision (mAP) of 0.93 in the morphological classification of Spiral or Elliptical galaxies for a set of 239,639 objects from the Galaxy Zoo sample and JPEG images from the Sloan Digital Sky Survey. As a direct use of segmentation, we test the model for deriving centroids of extended sources, reaching a precision better than 1.0 arcsecond. We also test the network under additive Gaussian noise. We find that the Mask R-CNN network is able to perform with accuracy over 92\% for a distribution scale of 76.5 counts. The repository with the model code is in the following url: https://github.com/hfarias/mask\_galaxy},
	language = {en},
	urldate = {2022-08-25},
	journal = {Astronomy and Computing, Volume 33, article id. 100420.},
	author = {Farias, H. and Ortiz, D. and Damke, G. and Jaque Arancibia, M. and Solar, M.},
	month = oct,
	year = {2020},
	pages = {100420},
}

@article{barchi_machine_2020,
	title = {Machine and {Deep} {Learning} applied to galaxy morphology - {A} comparative study},
	volume = {30},
	issn = {2213-1337},
	url = {https://ui.adsabs.harvard.edu/abs/2020A%26C....3000334B/abstract},
	doi = {10.1016/j.ascom.2019.100334},
	abstract = {Morphological classification is a key piece of information to define samples of galaxies aiming to study the large-scale structure of the universe. In essence, the challenge is to build up a robust methodology to perform a reliable morphological estimate from galaxy images. Here, we investigate how to substantially improve the galaxy classification within large datasets by mimicking human classification. We combine accurate visual classifications from the Galaxy Zoo project with machine and deep learning methodologies. We propose two distinct approaches for galaxy morphology: one based on non-parametric morphology and traditional machine learning algorithms; and another based on Deep Learning. To measure the input features for the traditional machine learning methodology, we have developed a system called CyMorph, with a novel non-parametric approach to study galaxy morphology. The main datasets employed comes from the Sloan Digital Sky Survey Data Release 7 (SDSS-DR7). We also discuss the class imbalance problem considering three classes. Performance of each model is mainly measured by Overall Accuracy (OA). A spectroscopic validation with astrophysical parameters is also provided for Decision Tree models to assess the quality of our morphological classification. In all of our samples, both Deep and Traditional Machine Learning approaches have over 94.5\% OA to classify galaxies in two classes (elliptical and spiral). We compare our classification with state-of-the-art morphological classification from literature. Considering only two classes separation, we achieve 99\% of overall accuracy in average when using our deep learning models, and 82\% when using three classes. We provide a catalog with 670,560 galaxies containing our best results, including morphological metrics and classification.},
	language = {en},
	urldate = {2022-08-25},
	journal = {Astronomy and Computing, Volume 30, article id. 100334.},
	author = {Barchi, P. H. and de Carvalho, R. R. and Rosa, R. R. and Sautter, R. A. and Soares-Santos, M. and Marques, B. a. D. and Clua, E. and Gonçalves, T. S. and de Sá-Freitas, C. and Moura, T. C.},
	month = jan,
	year = {2020},
	pages = {100334},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\CSEAI3M6\\Barchi et al. - 2020 - Machine and Deep Learning applied to galaxy morpho.pdf:application/pdf},
}

@phdthesis{beck_integrating_2018,
	title = {Integrating {Human} and {Machine} {Intelligence} in {Galaxy} {Morphology} {Classification} {Tasks}},
	url = {https://ui.adsabs.harvard.edu/abs/2018PhDT........16B},
	abstract = {The large flood of data flowing from observatories presents significant challenges to astronomy and cosmology--challenges that will only be magnified by projects currently under development. Growth in both volume and velocity of astrophysics data is accelerating: whereas the Sloan Digital Sky Survey (SDSS) has produced 60 terabytes of data in the last decade, the upcoming Large Synoptic Survey Telescope (LSST) plans to register 30 terabytes per night starting in the year 2020. Additionally, the Euclid Mission will acquire imaging for 5 x 107 resolvable galaxies. The field of galaxy evolution faces a particularly challenging future as complete understanding often cannot be reached without analysis of detailed morphological galaxy features. Historically, morphological analysis has relied on visual classification by astronomers, accessing the human brains capacity for advanced pattern recognition. However, this accurate but inefficient method falters when confronted with many thousands (or millions) of images. In the SDSS era, efforts to automate morphological classifications of galaxies (e.g., Conselice et al., 2000; Lotz et al., 2004) are reasonably successful and can distinguish between elliptical and disk-dominated galaxies with accuracies of 80\%. While this is statistically very useful, a key problem with these methods is that they often cannot say which 80\% of their samples are accurate. Furthermore, when confronted with the more complex task of identifying key substructure within galaxies, automated classification algorithms begin to fail. The Galaxy Zoo project uses a highly innovative approach to solving the scalability problem of visual classification. Displaying images of SDSS galaxies to volunteers via a simple and engaging web interface, www.galaxyzoo.org asks people to classify images by eye. Within the first year hundreds of thousands of members of the general public had classified each of the 1 million SDSS galaxies an average of 40 times. Galaxy Zoo thus solved both the visual classification problem of time efficiency and improved accuracy by producing a distribution of independent classifications for each galaxy. While crowd-sourced galaxy classifications have proven their worth, challenges remain before establishing this method as a critical and standard component of the data processing pipelines for the next generation of surveys. In particular, though innovative, crowd-sourcing techniques do not have the capacity to handle the data volume and rates expected in the next generation of surveys. These algorithms will be delegated to handle the majority of the classification tasks, freeing citizen scientists to contribute their efforts on subtler and more complex assignments. This thesis presents a solution through an integration of visual and automated classifications, preserving the best features of both human and machine. We demonstrate the effectiveness of such a system through a re-analysis of visual galaxy morphology classifications collected during the Galaxy Zoo 2 (GZ2) project. We reprocess the top-level question of the GZ2 decision tree with a Bayesian classification aggregation algorithm dubbed SWAP, originally developed for the Space Warps gravitational lens project. Through a simple binary classification scheme we increase the classification rate nearly 5-fold classifying 226,124 galaxies in 92 days of GZ2 project time while reproducing labels derived from GZ2 classification data with 95.7\% accuracy. We next combine this with a Random Forest machine learning algorithm that learns on a suite of non-parametric morphology indicators widely used for automated morphologies. We develop a decision engine that delegates tasks between human and machine and demonstrate that the combined system provides a factor of 11.4 increase in the classification rate, classifying 210,803 galaxies in just 32 days of GZ2 project time with 93.1\% accuracy. As the Random Forest algorithm requires a minimal amount of computational cost, this result has important implications for galaxy morphology identification tasks in the era of Euclid and other large-scale surveys.},
	urldate = {2022-08-25},
	author = {Beck, Melanie Renee},
	month = jan,
	year = {2018},
	note = {Publication Title: Ph.D. Thesis
ADS Bibcode: 2018PhDT........16B},
	keywords = {Artificial intelligence, Astrophysics, Information science},
}

@misc{dhar_data_nodate,
	title = {Data {Science} and {Prediction}},
	url = {https://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/abstract},
	abstract = {Big data promises automated actionable knowledge creation and predictive models for use by both humans and computers.},
	language = {en},
	urldate = {2022-10-10},
	author = {Dhar, Vasant},
	file = {Snapshot:C\:\\Users\\rober\\Zotero\\storage\\KN2KR597\\abstract.html:text/html},
}


@book{suthaharan_machine_2015,
	address = {New York, NY},
	edition = {1st ed. 2016},
	series = {Integrated {Series} in {Information} {Systems}},
	title = {Machine {Learning} {Models} and {Algorithms} for {Big} {Data} {Classification}: {Thinking} with {Examples} for {Effective} {Learning}},
	volume = {36},
	isbn = {978-1-4899-7640-6},
	shorttitle = {Machine {Learning} {Models} and {Algorithms} for {Big} {Data} {Classification}},
	abstract = {This book presents machine learning models and algorithms to address big data classification problems. Existing machine learning techniques like the decision tree (a hierarchical approach), random forest (an ensemble hierarchical approach), and deep learning (a layered approach) are highly suitable for the system that can handle such problems. This book helps readers, especially students and newcomers to the field of big data and machine learning, to gain a quick understanding of the techniques and technologies; therefore, the theory, examples, and programs (Matlab and R) presented in this book have been simplified, hardcoded, repeated, or spaced for improvements. They provide vehicles to test and understand the complicated concepts of various topics in the field. It is expected that the readers adopt these programs to experiment with the examples, and then modify or write their own programs toward advancing their knowledge for solving more complex and challenging problems. The presentation format of this book focuses on simplicity, readability, and dependability so that both undergraduate and graduate students as well as new researchers, developers, and practitioners in this field can easily trust and grasp the concepts, and learn them effectively. It has been written to reduce the mathematical complexity and help the vast majority of readers to understand the topics and get interested in the field. This book consists of four parts, with the total of 14 chapters. The first part mainly focuses on the topics that are needed to help analyze and understand data and big data. The second part covers the topics that can explain the systems required for processing big data. The third part presents the topics required to understand and select machine learning techniques to classify big data. Finally, the fourth part concentrates on the topics that explain the scaling-up machine learning, an important solution for modern big data problems.},
	language = {eng},
	publisher = {Springer},
	author = {Suthaharan, Shan},
	year = {2015},
	doi = {10.1007/978-1-4899-7641-3},
	note = {ISSN: 1571-0270},
	keywords = {Artificial Intelligence, Big data, Business and Management, Database Management, Electronic data processing, Machine theory, Management, Management science},
}

@misc{noauthor_sdss_nodate,
	title = {{SDSS} {Instruments}},
	url = {http://skyserver.sdss.org/dr1/en/sdss/instruments/instruments.asp},
	urldate = {2022-10-12},
	file = {SDSS Instruments:C\:\\Users\\rober\\Zotero\\storage\\LKY3HBJP\\instruments.html:text/html},
}

@article{possel_beginners_2020,
	title = {A {Beginner}'s {Guide} to {Working} with {Astronomical} {Data}},
	volume = {3},
	issn = {2565-6120},
	url = {http://arxiv.org/abs/1905.13189},
	doi = {10.21105/astro.1905.13189},
	abstract = {This elementary review covers the basics of working with astronomical data, notably with images, spectra and higher-level (catalog) data. The basic concepts and tools are presented using both application software (DS9 and TOPCAT) and Python. The level of presentation is suitable for undergraduate students, but should also be accessible to advanced high school students.},
	language = {en},
	number = {1},
	urldate = {2022-10-12},
	journal = {The Open Journal of Astrophysics},
	author = {Pössel, Markus},
	month = jan,
	year = {2020},
	note = {arXiv:1905.13189 [astro-ph, physics:physics]},
	keywords = {Astrophysics - Instrumentation and Methods for Astrophysics, Physics - Physics Education},
	pages = {10.21105/astro.1905.13189},
	file = {Pössel - 2020 - A Beginner's Guide to Working with Astronomical Da.pdf:C\:\\Users\\rober\\Zotero\\storage\\BNYX7EI6\\Pössel - 2020 - A Beginner's Guide to Working with Astronomical Da.pdf:application/pdf},
}

@misc{noauthor_voyages_nodate,
	title = {Voyages {\textbar} {Types} of {Data}},
	url = {https://voyages.sdss.org/preflight/capturing-recording-light/types-of-data/},
	language = {en-US},
	urldate = {2022-10-12},
	file = {Snapshot:C\:\\Users\\rober\\Zotero\\storage\\3NJG8P6X\\types-of-data.html:text/html},
}


@book{i_appenzeller_immo_author_introduction_2013,
	address = {Cambridge},
	series = {Cambridge observing handbooks for research astronomers},
	title = {Introduction to astronomical spectroscopy},
	isbn = {978-1-316-08957-6},
	abstract = {Historical remarks -- Spectroscopy in present-day astronomy -- Basic physics of spectral measurements -- Optical-range grafting and prism spectrometers -- Other techniques for the optical spectral range -- Preparing and reducing optical observation -- UV, X-ray, and gamma spectroscopy -- Spectroscopy at radio wavelengths -- Special techniques of the FIR and submillimeter range -- New developments and future prospects., Spectroscopy is the principal tool used in astronomy to investigate the Universe beyond Earth's atmosphere. Through the analysis of electromagnetic radiation, spectrographs enable observers to assess the chemical composition, kinematics and local physical properties of distant stars, nebulae and galaxies. Thoroughly illustrated and clearly written, this handbook offers a practical and comprehensive guide to the different spectroscopic methods used in all branches of astronomy, at all wavelengths from radio to gamma-ray and from ground and space-borne instruments. After a historical overview of the field, the central chapters navigate the various types of hardware used in spectroscopy. In-depth descriptions of modern techniques and their benefits and drawbacks help you choose the most promising observation strategy. The handbook finishes by assessing new technologies and future prospects for deep-sky observation. This text is an ideal reference for today's graduate students and active researchers, as well as those designing or operating spectroscopic instruments.},
	language = {eng},
	number = {9},
	publisher = {University Press},
	author = {{I Appenzeller (Immo) author}},
	year = {2013},
	keywords = {Astronomical spectroscopy},
}

@article{blanton_sloan_2017,
	title = {Sloan {Digital} {Sky} {Survey} {IV}: {Mapping} the {Milky} {Way}, {Nearby} {Galaxies}, and the {Distant} {Universe}},
	volume = {154},
	issn = {0004-6256},
	shorttitle = {Sloan {Digital} {Sky} {Survey} {IV}},
	url = {https://ui.adsabs.harvard.edu/abs/2017AJ....154...28B},
	doi = {10.3847/1538-3881/aa7567},
	abstract = {We describe the Sloan Digital Sky Survey IV (SDSS-IV), a project encompassing three major spectroscopic programs. The Apache Point Observatory Galactic Evolution Experiment 2 (APOGEE-2) is observing hundreds of thousands of Milky Way stars at high resolution and high signal-to-noise ratios in the near-infrared. The Mapping Nearby Galaxies at Apache Point Observatory (MaNGA) survey is obtaining spatially resolved spectroscopy for thousands of nearby galaxies (median z∼ 0.03). The extended Baryon Oscillation Spectroscopic Survey (eBOSS) is mapping the galaxy, quasar, and neutral gas distributions between z∼ 0.6 and 3.5 to constrain cosmology using baryon acoustic oscillations, redshift space distortions, and the shape of the power spectrum. Within eBOSS, we are conducting two major subprograms: the SPectroscopic IDentification of eROSITA Sources (SPIDERS), investigating X-ray AGNs and galaxies in X-ray clusters, and the Time Domain Spectroscopic Survey (TDSS), obtaining spectra of variable sources. All programs use the 2.5 m Sloan Foundation Telescope at the Apache Point Observatory; observations there began in Summer 2014. APOGEE-2 also operates a second near-infrared spectrograph at the 2.5 m du Pont Telescope at Las Campanas Observatory, with observations beginning in early 2017. Observations at both facilities are scheduled to continue through 2020. In keeping with previous SDSS policy, SDSS-IV provides regularly scheduled public data releases; the first one, Data Release 13, was made available in 2016 July.},
	urldate = {2022-10-12},
	journal = {The Astronomical Journal},
	author = {Blanton, Michael R. and Bershady, Matthew A. and Abolfathi, Bela and Albareti, Franco D. and Allende Prieto, Carlos and Almeida, Andres and Alonso-García, Javier and Anders, Friedrich and Anderson, Scott F. and Andrews, Brett and Aquino-Ortíz, Erik and Aragón-Salamanca, Alfonso and Argudo-Fernández, Maria and Armengaud, Eric and Aubourg, Eric and Avila-Reese, Vladimir and Badenes, Carles and Bailey, Stephen and Barger, Kathleen A. and Barrera-Ballesteros, Jorge and Bartosz, Curtis and Bates, Dominic and Baumgarten, Falk and Bautista, Julian and Beaton, Rachael and Beers, Timothy C. and Belfiore, Francesco and Bender, Chad F. and Berlind, Andreas A. and Bernardi, Mariangela and Beutler, Florian and Bird, Jonathan C. and Bizyaev, Dmitry and Blanc, Guillermo A. and Blomqvist, Michael and Bolton, Adam S. and Boquien, Médéric and Borissova, Jura and van den Bosch, Remco and Bovy, Jo and Brandt, William N. and Brinkmann, Jonathan and Brownstein, Joel R. and Bundy, Kevin and Burgasser, Adam J. and Burtin, Etienne and Busca, Nicolás G. and Cappellari, Michele and Delgado Carigi, Maria Leticia and Carlberg, Joleen K. and Carnero Rosell, Aurelio and Carrera, Ricardo and Chanover, Nancy J. and Cherinka, Brian and Cheung, Edmond and Gómez Maqueo Chew, Yilen and Chiappini, Cristina and Choi, Peter Doohyun and Chojnowski, Drew and Chuang, Chia-Hsun and Chung, Haeun and Cirolini, Rafael Fernando and Clerc, Nicolas and Cohen, Roger E. and Comparat, Johan and da Costa, Luiz and Cousinou, Marie-Claude and Covey, Kevin and Crane, Jeffrey D. and Croft, Rupert A. C. and Cruz-Gonzalez, Irene and Garrido Cuadra, Daniel and Cunha, Katia and Damke, Guillermo J. and Darling, Jeremy and Davies, Roger and Dawson, Kyle and de la Macorra, Axel and Dell'Agli, Flavia and De Lee, Nathan and Delubac, Timothée and Di Mille, Francesco and Diamond-Stanic, Aleks and Cano-Díaz, Mariana and Donor, John and Downes, Juan José and Drory, Niv and du Mas des Bourboux, Hélion and Duckworth, Christopher J. and Dwelly, Tom and Dyer, Jamie and Ebelke, Garrett and Eigenbrot, Arthur D. and Eisenstein, Daniel J. and Emsellem, Eric and Eracleous, Mike and Escoffier, Stephanie and Evans, Michael L. and Fan, Xiaohui and Fernández-Alvar, Emma and Fernandez-Trincado, J. G. and Feuillet, Diane K. and Finoguenov, Alexis and Fleming, Scott W. and Font-Ribera, Andreu and Fredrickson, Alexander and Freischlad, Gordon and Frinchaboy, Peter M. and Fuentes, Carla E. and Galbany, Lluís and Garcia-Dias, R. and García-Hernández, D. A. and Gaulme, Patrick and Geisler, Doug and Gelfand, Joseph D. and Gil-Marín, Héctor and Gillespie, Bruce A. and Goddard, Daniel and Gonzalez-Perez, Violeta and Grabowski, Kathleen and Green, Paul J. and Grier, Catherine J. and Gunn, James E. and Guo, Hong and Guy, Julien and Hagen, Alex and Hahn, ChangHoon and Hall, Matthew and Harding, Paul and Hasselquist, Sten and Hawley, Suzanne L. and Hearty, Fred and Gonzalez Hernández, Jonay I. and Ho, Shirley and Hogg, David W. and Holley-Bockelmann, Kelly and Holtzman, Jon A. and Holzer, Parker H. and Huehnerhoff, Joseph and Hutchinson, Timothy A. and Hwang, Ho Seong and Ibarra-Medel, Héctor J. and da Silva Ilha, Gabriele and Ivans, Inese I. and Ivory, KeShawn and Jackson, Kelly and Jensen, Trey W. and Johnson, Jennifer A. and Jones, Amy and Jönsson, Henrik and Jullo, Eric and Kamble, Vikrant and Kinemuchi, Karen and Kirkby, David and Kitaura, Francisco-Shu and Klaene, Mark and Knapp, Gillian R. and Kneib, Jean-Paul and Kollmeier, Juna A. and Lacerna, Ivan and Lane, Richard R. and Lang, Dustin and Law, David R. and Lazarz, Daniel and Lee, Youngbae and Le Goff, Jean-Marc and Liang, Fu-Heng and Li, Cheng and Li, Hongyu and Lian, Jianhui and Lima, Marcos and Lin, Lihwai and Lin, Yen-Ting and Bertran de Lis, Sara and Liu, Chao and de Icaza Lizaola, Miguel Angel C. and Long, Dan and Lucatello, Sara and Lundgren, Britt and MacDonald, Nicholas K. and Deconto Machado, Alice and MacLeod, Chelsea L. and Mahadevan, Suvrath and Geimba Maia, Marcio Antonio and Maiolino, Roberto and Majewski, Steven R. and Malanushenko, Elena and Malanushenko, Viktor and Manchado, Arturo and Mao, Shude and Maraston, Claudia and Marques-Chaves, Rui and Masseron, Thomas and Masters, Karen L. and McBride, Cameron K. and McDermid, Richard M. and McGrath, Brianne and McGreer, Ian D. and Medina Peña, Nicolás and Melendez, Matthew and Merloni, Andrea and Merrifield, Michael R. and Meszaros, Szabolcs and Meza, Andres and Minchev, Ivan and Minniti, Dante and Miyaji, Takamitsu and More, Surhud and Mulchaey, John and Müller-Sánchez, Francisco and Muna, Demitri and Munoz, Ricardo R. and Myers, Adam D. and Nair, Preethi and Nandra, Kirpal and Correa do Nascimento, Janaina and Negrete, Alenka and Ness, Melissa and Newman, Jeffrey A. and Nichol, Robert C. and Nidever, David L. and Nitschelm, Christian and Ntelis, Pierros and O'Connell, Julia E. and Oelkers, Ryan J. and Oravetz, Audrey and Oravetz, Daniel and Pace, Zach and Padilla, Nelson and Palanque-Delabrouille, Nathalie and Alonso Palicio, Pedro and Pan, Kaike and Parejko, John K. and Parikh, Taniya and Pâris, Isabelle and Park, Changbom and Patten, Alim Y. and Peirani, Sebastien and Pellejero-Ibanez, Marcos and Penny, Samantha and Percival, Will J. and Perez-Fournon, Ismael and Petitjean, Patrick and Pieri, Matthew M. and Pinsonneault, Marc and Pisani, Alice and Poleski, Radosław and Prada, Francisco and Prakash, Abhishek and Queiroz, Anna Bárbara de Andrade and Raddick, M. Jordan and Raichoor, Anand and Barboza Rembold, Sandro and Richstein, Hannah and Riffel, Rogemar A. and Riffel, Rogério and Rix, Hans-Walter and Robin, Annie C. and Rockosi, Constance M. and Rodríguez-Torres, Sergio and Roman-Lopes, A. and Román-Zúñiga, Carlos and Rosado, Margarita and Ross, Ashley J. and Rossi, Graziano and Ruan, John and Ruggeri, Rossana and Rykoff, Eli S. and Salazar-Albornoz, Salvador and Salvato, Mara and Sánchez, Ariel G. and Aguado, D. S. and Sánchez-Gallego, José R. and Santana, Felipe A. and Santiago, Basílio Xavier and Sayres, Conor and Schiavon, Ricardo P. and da Silva Schimoia, Jaderson and Schlafly, Edward F. and Schlegel, David J. and Schneider, Donald P. and Schultheis, Mathias and Schuster, William J. and Schwope, Axel and Seo, Hee-Jong and Shao, Zhengyi and Shen, Shiyin and Shetrone, Matthew and Shull, Michael and Simon, Joshua D. and Skinner, Danielle and Skrutskie, M. F. and Slosar, Anže and Smith, Verne V. and Sobeck, Jennifer S. and Sobreira, Flavia and Somers, Garrett and Souto, Diogo and Stark, David V. and Stassun, Keivan and Stauffer, Fritz and Steinmetz, Matthias and Storchi-Bergmann, Thaisa and Streblyanska, Alina and Stringfellow, Guy S. and Suárez, Genaro and Sun, Jing and Suzuki, Nao and Szigeti, Laszlo and Taghizadeh-Popp, Manuchehr and Tang, Baitian and Tao, Charling and Tayar, Jamie and Tembe, Mita and Teske, Johanna and Thakar, Aniruddha R. and Thomas, Daniel and Thompson, Benjamin A. and Tinker, Jeremy L. and Tissera, Patricia and Tojeiro, Rita and Hernandez Toledo, Hector and de la Torre, Sylvain and Tremonti, Christy and Troup, Nicholas W. and Valenzuela, Octavio and Martinez Valpuesta, Inma and Vargas-González, Jaime and Vargas-Magaña, Mariana and Vazquez, Jose Alberto and Villanova, Sandro and Vivek, M. and Vogt, Nicole and Wake, David and Walterbos, Rene and Wang, Yuting and Weaver, Benjamin Alan and Weijmans, Anne-Marie and Weinberg, David H. and Westfall, Kyle B. and Whelan, David G. and Wild, Vivienne and Wilson, John and Wood-Vasey, W. M. and Wylezalek, Dominika and Xiao, Ting and Yan, Renbin and Yang, Meng and Ybarra, Jason E. and Yèche, Christophe and Zakamska, Nadia and Zamora, Olga and Zarrouk, Pauline and Zasowski, Gail and Zhang, Kai and Zhao, Gong-Bo and Zheng, Zheng and Zheng, Zheng and Zhou, Xu and Zhou, Zhi-Min and Zhu, Guangtun B. and Zoccali, Manuela and Zou, Hu},
	month = jul,
	year = {2017},
	note = {ADS Bibcode: 2017AJ....154...28B},
	keywords = {Astrophysics - Astrophysics of Galaxies, cosmology: observations, galaxies: general, Galaxy: general, instrumentation: spectrographs, stars: general, surveys},
	pages = {28},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\VVZEQHVB\\Blanton et al. - 2017 - Sloan Digital Sky Survey IV Mapping the Milky Way.pdf:application/pdf},
}

@misc{willett_galaxy_2013,
	title = {Galaxy {Zoo} 2: detailed morphological classifications for 304,122 galaxies from the {Sloan} {Digital} {Sky} {Survey}},
	shorttitle = {Galaxy {Zoo} 2},
	url = {http://arxiv.org/abs/1308.3496},
	doi = {10.1093/mnras/stt1458},
	abstract = {We present the data release for Galaxy Zoo 2 (GZ2), a citizen science project with more than 16 million morphological classifications of 304,122 galaxies drawn from the Sloan Digital Sky Survey. Morphology is a powerful probe for quantifying a galaxy's dynamical history; however, automatic classifications of morphology (either by computer analysis of images or by using other physical parameters as proxies) still have drawbacks when compared to visual inspection. The large number of images available in current surveys makes visual inspection of each galaxy impractical for individual astronomers. GZ2 uses classifications from volunteer citizen scientists to measure morphologies for all galaxies in the DR7 Legacy survey with m\_r{\textgreater}17, in addition to deeper images from SDSS Stripe 82. While the original Galaxy Zoo project identified galaxies as early-types, late-types, or mergers, GZ2 measures finer morphological features. These include bars, bulges, and the shapes of edge-on disks, as well as quantifying the relative strengths of galactic bulges and spiral arms. This paper presents the full public data release for the project, including measures of accuracy and bias. The majority ({\textgreater}90\%) of GZ2 classifications agree with those made by professional astronomers, especially for morphological T-types, strong bars, and arm curvature. Both the raw and reduced data products can be obtained in electronic format at http://data.galaxyzoo.org .},
	urldate = {2022-10-13},
	author = {Willett, Kyle W. and Lintott, Chris J. and Bamford, Steven P. and Masters, Karen L. and Simmons, Brooke D. and Casteels, Kevin R. V. and Edmondson, Edward M. and Fortson, Lucy F. and Kaviraj, Sugata and Keel, William C. and Melvin, Thomas and Nichol, Robert C. and Raddick, M. Jordan and Schawinski, Kevin and Simpson, Robert J. and Skibba, Ramin A. and Smith, Arfon M. and Thomas, Daniel},
	month = aug,
	year = {2013},
	note = {arXiv:1308.3496 [astro-ph]},
	keywords = {Astrophysics - Cosmology and Nongalactic Astrophysics},
	file = {arXiv Fulltext PDF:C\:\\Users\\rober\\Zotero\\storage\\ZY8VFI94\\Willett et al. - 2013 - Galaxy Zoo 2 detailed morphological classificatio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\rober\\Zotero\\storage\\ICIM48PV\\1308.html:text/html},
}

@article{lintott_galaxy_2008,
	title = {Galaxy {Zoo}: morphologies derived from visual inspection of galaxies from the {Sloan} {Digital} {Sky} {Survey}},
	volume = {389},
	issn = {0035-8711},
	shorttitle = {Galaxy {Zoo}},
	url = {https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L},
	doi = {10.1111/j.1365-2966.2008.13689.x},
	abstract = {In order to understand the formation and subsequent evolution of galaxies one must first distinguish between the two main morphological classes of massive systems: spirals and early-type systems. This paper introduces a project, Galaxy Zoo, which provides visual morphological classifications for nearly one million galaxies, extracted from the Sloan Digital Sky Survey (SDSS). This achievement was made possible by inviting the general public to visually inspect and classify these galaxies via the internet. The project has obtained more than 4 × 107 individual classifications made by {\textasciitilde}105 participants. We discuss the motivation and strategy for this project, and detail how the classifications were performed and processed. We find that Galaxy Zoo results are consistent with those for subsets of SDSS galaxies classified by professional astronomers, thus demonstrating that our data provide a robust morphological catalogue. Obtaining morphologies by direct visual inspection avoids introducing biases associated with proxies for morphology such as colour, concentration or structural parameters. In addition, this catalogue can be used to directly compare SDSS morphologies with older data sets. The colour-magnitude diagrams for each morphological class are shown, and we illustrate how these distributions differ from those inferred using colour alone as a proxy for morphology. This publication has been made possible by the participation of more than 100000 volunteers in the Galaxy Zoo project. Their contributions are individually acknowledged at http://www.galaxyzoo.org/Volunteers.aspx E-mail: cjl@astro.ox.ac.uk (CJL); kevins@astro.ox.ac.uk (KS)},
	urldate = {2022-10-13},
	journal = {Monthly Notices of the Royal Astronomical Society},
	author = {Lintott, Chris J. and Schawinski, Kevin and Slosar, Anže and Land, Kate and Bamford, Steven and Thomas, Daniel and Raddick, M. Jordan and Nichol, Robert C. and Szalay, Alex and Andreescu, Dan and Murray, Phil and Vandenberg, Jan},
	month = sep,
	year = {2008},
	note = {ADS Bibcode: 2008MNRAS.389.1179L},
	keywords = {Astrophysics, cD, galaxies: elliptical and lenticular, galaxies: general, galaxies: spiral, methods: data analysis},
	pages = {1179--1189},
	file = {Full Text PDF:C\:\\Users\\rober\\Zotero\\storage\\ZC2XIMI5\\Lintott et al. - 2008 - Galaxy Zoo morphologies derived from visual inspe.pdf:application/pdf},
}


@article{lemley_smart_2017,
	title = {Smart {Augmentation} {Learning} an {Optimal} {Data} {Augmentation} {Strategy}},
	volume = {5},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2017.2696121},
	abstract = {A recurring problem faced when training neural networks is that there is typically not enough data to maximize the generalization capability of deep neural networks. There are many techniques to address this, including data augmentation, dropout, and transfer learning. In this paper, we introduce an additional method, which we call smart augmentation and we show how to use it to increase the accuracy and reduce over fitting on a target network. Smart augmentation works, by creating a network that learns how to generate augmented data during the training process of a target network in a way that reduces that networks loss. This allows us to learn augmentations that minimize the error of that network. Smart augmentation has shown the potential to increase accuracy by demonstrably significant measures on all data sets tested. In addition, it has shown potential to achieve similar or improved performance levels with significantly smaller network sizes in a number of tested cases.},
	journal = {IEEE Access},
	author = {Lemley, Joseph and Bazrafkan, Shabab and Corcoran, Peter},
	year = {2017},
	note = {Conference Name: IEEE Access},
	keywords = {Artificial intelligence, artificial neural networks, Biological neural networks, computer vision supervised learning, Data models, Electronic mail, image databases, Informatics, machine learning, Machine learning, machine learning algorithms, Training},
	pages = {5858--5869},
}
